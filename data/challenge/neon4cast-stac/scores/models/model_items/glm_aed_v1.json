{
  "stac_version": "1.0.0",
  "stac_extensions": [
    "https://stac-extensions.github.io/table/v1.2.0/schema.json"
  ],
  "type": "Feature",
  "id": "glm_aed_v1",
  "bbox": [
    [
      -156.6194,
      71.2824,
      -66.7987,
      71.2824
    ]
  ],
  "geometry": {
    "type": "MultiPoint",
    "coordinates": [
      [37.3032, -79.8372]
    ]
  },
  "properties": {
    "description": "\nmodel info: GLM-AED with Ensemble Kalman Filter as implemented in FLARE.  This version used DA to update model states but not model parameters.\n\nSites: fcre\n\nVariables: DIC_mgL_sample, DO_mgL_mean, NH4_ugL_sample, SRP_ugL_sample, Temp_C_mean, fDOM_QSU_mean, Chla_ugL_mean, Secchi_m_sample, Bloom_binary_mean",
    "start_datetime": "2023-10-14",
    "end_datetime": "2023-12-01",
    "providers": [
      {
        "url": "pending",
        "name": "pending",
        "roles": [
          "producer",
          "processor",
          "licensor"
        ]
      },
      {
        "url": "https://www.ecoforecastprojectvt.org",
        "name": "Ecoforecast Challenge",
        "roles": [
          "host"
        ]
      }
    ],
    "license": "CC0-1.0",
    "keywords": [
      "Forecasting",
      "vera4cast",
      "DIC_mgL_sample, DO_mgL_mean, NH4_ugL_sample, SRP_ugL_sample, Temp_C_mean, fDOM_QSU_mean, Chla_ugL_mean, Secchi_m_sample, Bloom_binary_mean"
    ],
    "table:columns": [
      {
        "name": "reference_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that the forecast was initiated (horizon = 0)"
      },
      {
        "name": "site_id",
        "type": "string",
        "description": "For forecasts that are not on a spatial grid, use of a site dimension that maps to a more detailed geometry (points, polygons, etc.) is allowable. In general this would be documented in the external metadata (e.g., alook-up table that provides lon and lat); however in netCDF this could be handled by the CF Discrete Sampling Geometry data model."
      },
      {
        "name": "datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime of the forecasted value (ISO 8601)"
      },
      {
        "name": "family",
        "type": "string",
        "description": "For ensembles: “ensemble.” Default value if unspecified For probability distributions: Name of the statistical distribution associated with the reported statistics. The “sample” distribution is synonymous with “ensemble.” For summary statistics: “summary.”If this dimension does not vary, it is permissible to specify family as a variable attribute if the file format being used supports this (e.g.,netCDF)."
      },
      {
        "name": "pub_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that forecast was submitted"
      },
      {
        "name": "depth_m",
        "type": "double",
        "description": "depth (meters) in water column of prediction"
      },
      {
        "name": "observation",
        "type": "double",
        "description": "observed value for variable"
      },
      {
        "name": "crps",
        "type": "double",
        "description": "crps forecast score"
      },
      {
        "name": "logs",
        "type": "double",
        "description": "logs forecast score"
      },
      {
        "name": "mean",
        "type": "double",
        "description": "mean forecast prediction"
      },
      {
        "name": "median",
        "type": "double",
        "description": "median forecast prediction"
      },
      {
        "name": "sd",
        "type": "double",
        "description": "standard deviation forecasts"
      },
      {
        "name": "quantile97.5",
        "type": "double",
        "description": "upper 97.5 percentile value of forecast"
      },
      {
        "name": "quantile02.5",
        "type": "double",
        "description": "upper 2.5 percentile value of forecast"
      },
      {
        "name": "quantile90",
        "type": "double",
        "description": "upper 90 percentile value of forecast"
      },
      {
        "name": "quantile10",
        "type": "double",
        "description": "upper 10 percentile value of forecast"
      },
      {
        "name": "project_id",
        "type": "string",
        "description": "unique project identifier"
      },
      {
        "name": "duration",
        "type": "string",
        "description": "temporal duration of forecast (hourly = PT1H, daily = P1D, etc.); follows ISO 8601 duration convention"
      },
      {
        "name": "variable",
        "type": "string",
        "description": "name of forecasted variable"
      },
      {
        "name": "model_id",
        "type": "string",
        "description": "unique model identifier"
      },
      {
        "name": "date",
        "type": "string",
        "description": "ISO 8601 (ISO 2019) date of the predicted value; follows CF convention http://cfconventions.org/cf-conventions/cf-conventions.html#time-coordinate. This variable was called time before v0.5of the EFI convention. For time-integrated variables (e.g., cumulative net primary productivity), one should specify the start_datetime and end_datetime as two variables, instead of the single datetime. If this is not provided the datetime is assumed to be the MIDPOINT of the integration period."
      }
    ]
  },
  "collection": "scores",
  "links": [
    {
      "rel": "collection",
      "href": "../collection.json",
      "type": "application/json",
      "title": "glm_aed_v1"
    },
    {
      "rel": "root",
      "href": "../../../catalog.json",
      "type": "application/json",
      "title": "Forecast Catalog"
    },
    {
      "rel": "parent",
      "href": "../collection.json",
      "type": "application/json",
      "title": "glm_aed_v1"
    },
    {
      "rel": "self",
      "href": "glm_aed_v1.json",
      "type": "application/json",
      "title": "Model Forecast"
    }
  ],
  "assets": {
    "1": {
      "type": "application/json",
      "title": "Model Metadata",
      "href": "https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/metadata/model_id/glm_aed_v1.json",
      "description": "Use `jsonlite::fromJSON()` to download the model metadata JSON file. This R code will return metadata provided during the model registration.\n      \n\n### R\n\n```{r}\n# Use code below\n\nmodel_metadata <- jsonlite::fromJSON(\"https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/metadata/model_id/glm_aed_v1.json\")\n\n"
    },
    "2": {
      "type": "application/x-parquet",
      "title": "Database Access for DIC_mgL_sample daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=DIC_mgL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=DIC_mgL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "3": {
      "type": "application/x-parquet",
      "title": "Database Access for DO_mgL_mean daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=DO_mgL_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=DO_mgL_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "4": {
      "type": "application/x-parquet",
      "title": "Database Access for NH4_ugL_sample daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=NH4_ugL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=NH4_ugL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "5": {
      "type": "application/x-parquet",
      "title": "Database Access for SRP_ugL_sample daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=SRP_ugL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=SRP_ugL_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "6": {
      "type": "application/x-parquet",
      "title": "Database Access for Temp_C_mean daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Temp_C_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Temp_C_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "7": {
      "type": "application/x-parquet",
      "title": "Database Access for fDOM_QSU_mean daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=fDOM_QSU_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=fDOM_QSU_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "8": {
      "type": "application/x-parquet",
      "title": "Database Access for Chla_ugL_mean daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Chla_ugL_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Chla_ugL_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "9": {
      "type": "application/x-parquet",
      "title": "Database Access for Secchi_m_sample daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Secchi_m_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Secchi_m_sample/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "10": {
      "type": "application/x-parquet",
      "title": "Database Access for Bloom_binary_mean daily",
      "href": "s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Bloom_binary_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(s3://anonymous@bio230121-bucket01/vera4cast/scores/parquet/duration=P1D/variable=Bloom_binary_mean/model_id=glm_aed_v1?endpoint_override=renc.osn.xsede.org)\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    }
  }
}
